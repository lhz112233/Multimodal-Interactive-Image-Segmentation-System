import gradio as gr
import torch
import clip
from segment_anything import build_sam, SamAutomaticMaskGenerator
import numpy as np
from PIL import Image, ImageDraw
import os
from datetime import datetime
import pandas as pd
from PIL import Image
from io import BytesIO

# åˆå§‹åŒ–è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åŠ è½½æ¨¡å‹
print('å¼€å§‹åŠ è½½CLIPæ¨¡å‹...')
clip_model, preprocess = clip.load("ViT-B/32", device=device)
print('CLIPæ¨¡å‹åŠ è½½å®Œæˆ')

# åŠ è½½SAMæ¨¡å‹
print('å¼€å§‹åŠ è½½SAMæ¨¡å‹...')
model_path = os.path.join(os.path.dirname(__file__), "path/model3.pth")  # è¯·ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®
if os.path.exists(model_path):
    sam = build_sam(checkpoint=model_path)
    mask_generator = SamAutomaticMaskGenerator(sam)
    print('SAMæ¨¡å‹åŠ è½½å®Œæˆ')
else:
    raise FileNotFoundError(f"Model file not found at {model_path}")


def convert_box_xywh_to_xyxy(box):
    return [box[0], box[1], box[0] + box[2], box[1] + box[3]]


def segment_image(image, segmentation_mask):
    image_array = np.array(image)
    segmented_image_array = np.zeros_like(image_array)
    segmented_image_array[segmentation_mask] = image_array[segmentation_mask]
    segmented_image = Image.fromarray(segmented_image_array)
    black_image = Image.new("RGB", image.size, (0, 0, 0))
    transparency_mask = Image.fromarray(segmentation_mask.astype(np.uint8) * 255)
    black_image.paste(segmented_image, mask=transparency_mask)
    return black_image


@torch.no_grad()
def retrieve_images(elements: list, search_terms: list, process_info):
    start_time = datetime.now()

    # é¢„å¤„ç†æ‰€æœ‰å›¾åƒ
    preprocessed_images = [preprocess(img).to(device) for img in elements]
    stacked_images = torch.stack(preprocessed_images)

    # ç¼–ç æ–‡æœ¬
    tokenized_text = clip.tokenize(search_terms).to(device)

    # æå–ç‰¹å¾
    image_features = clip_model.encode_image(stacked_images)
    text_features = clip_model.encode_text(tokenized_text)

    # å½’ä¸€åŒ–ç‰¹å¾
    image_features /= image_features.norm(dim=-1, keepdim=True)
    text_features /= text_features.norm(dim=-1, keepdim=True)

    # è®¡ç®—ç›¸ä¼¼åº¦å¹¶å–æœ€å¤§å€¼
    probs = 100.0 * (image_features @ text_features.T)
    max_probs, _ = torch.max(probs, dim=1)
    scores = max_probs.softmax(dim=0)

    process_info["clip_time"] = (datetime.now() - start_time).total_seconds()
    return scores


def createOverlay(image, masks, indices):
    original_image = image.convert("RGBA")
    overlay_image = Image.new("RGBA", original_image.size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(overlay_image)
    for seg_idx in indices:
        mask = masks[seg_idx]["segmentation"]
        mask_image = Image.fromarray(mask.astype(np.uint8) * 255)
        draw.bitmap((0, 0), mask_image, fill=(255, 0, 0, 200))
    return Image.alpha_composite(original_image, overlay_image)


def process_image_batch(images_list, search_text, show_mask, alpha, threshold, box_nms_thresh):
    process_info = {"timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
    mask_generator.box_nms_thresh = box_nms_thresh

    # åˆ†å‰²æœç´¢å…³é”®è¯
    search_terms = [term.strip() for term in search_text.split(',') if term.strip()]
    if not search_terms:
        return [None] * len(images_list), pd.DataFrame(), "æœªè¾“å…¥æœ‰æ•ˆæœç´¢å…³é”®è¯"

    result_images = []
    all_logs = []
    for idx, image_file in enumerate(images_list, 1):
        try:
            # ç›´æ¥æ‰“å¼€ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶
            image = Image.open(image_file)
            image_rgb = image.convert("RGB")
            image_np = np.array(image_rgb)

            # ç”Ÿæˆåˆ†å‰²æ©ç 
            masks = mask_generator.generate(image_np)
            cropped_boxes = [segment_image(image_rgb, m["segmentation"]).crop(convert_box_xywh_to_xyxy(m["bbox"]))
                             for m in masks]

            # æ£€ç´¢åŒ¹é…åŒºåŸŸ
            scores = retrieve_images(cropped_boxes, search_terms, process_info)
            indices = [i for i, v in enumerate(scores) if v > threshold]

            # ç”Ÿæˆç»“æœå›¾åƒ
            result_img = createOverlay(image_rgb, masks, indices) if show_mask else image_rgb
            result_images.append(result_img)

            log = f"å›¾ç‰‡{idx}: æ£€æµ‹åˆ°{len(indices)}ä¸ªåŒ¹é…åŒºåŸŸ | è€—æ—¶{process_info['clip_time']:.2f}s"
            all_logs.append(log)

        except Exception as e:
            all_logs.append(f"å›¾ç‰‡{idx}å¤„ç†å¤±è´¥: {str(e)}")
            result_images.append(None)

    log_df = pd.DataFrame({"å¤„ç†æ—¥å¿—": all_logs})
    stats = f"å…±å¤„ç†{len(images_list)}å¼ å›¾ç‰‡ | æ€»è€—æ—¶{sum([process_info.get('clip_time', 0)]):.2f}ç§’"
    return result_images, log_df, stats


def main_interface():
    with gr.Blocks(title="æ™ºèƒ½å›¾åƒåˆ†å‰²ç³»ç»Ÿ") as demo:
        gr.Image("assets/logo.png", scale=1)
        gr.HTML("<div style='text-align: center;'>ğŸ–¼ï¸ æ™ºèƒ½å›¾åƒåˆ†å‰²ç³»ç»Ÿ</div>")
        gr.Markdown("ä¸Šä¼ å›¾ç‰‡å¹¶è¾“å…¥å…³é”®è¯ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ ‡è®°åŒ¹é…åŒºåŸŸ")

        with gr.Row():  
            input_col = gr.Column()
            output_col = gr.Column()

            with input_col:
                input_images = gr.Files(label="ä¸Šä¼ å›¾ç‰‡", file_types=["image"], file_count="multiple")
                search_text = gr.Textbox(label="æœç´¢å†…å®¹", placeholder="ä¾‹: äºº, ç‹—, æ±½è½¦...", value="Please help me segment a pig.")
                threshold = gr.Slider(0.01, 0.5, value=0.1, label="åŒ¹é…é˜ˆå€¼")
                process_btn = gr.Button("ğŸš€ å¼€å§‹å¤„ç†", variant="primary")

            with output_col:
                output_gallery = gr.Gallery(label="å¤„ç†ç»“æœ", columns=3, height=500)
                logs = gr.Dataframe(label="å¤„ç†æ—¥å¿—", headers=["æ—¥å¿—"])
                stats = gr.Textbox(label="ç»Ÿè®¡ä¿¡æ¯")

        process_btn.click(
            fn=process_image_batch,
            inputs=[input_images, search_text, gr.Checkbox(True, visible=False), gr.Number(0.5, visible=False),
                    threshold, gr.Number(0.7, visible=False)],
            outputs=[output_gallery, logs, stats]
        )

    return demo


if __name__ == "__main__":
    demo = main_interface()
    demo.launch(share=True)